{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b42e221",
   "metadata": {},
   "source": [
    "### Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80d9f585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      
     ]
    }
   ],
   "source": [
    "!pip install easyocr\n",
    "!pip install torch torchvision torchaudio  # already needed\n",
    "!pip install transformers\n",
    "!pip install sentence-transformers\n",
    "!pip install rank_bm25\n",
    "!pip install python-dotenv\n",
    "!pip install groq\n",
    "!pip install pillow\n",
    "!pip install pymupdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457484a3",
   "metadata": {},
   "source": [
    "### Load .env and Groq API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d446254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff386a1",
   "metadata": {},
   "source": [
    "### Load EasyOCR Model for Handwriting OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f37a43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% Complete"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "reader = easyocr.Reader(['en'], gpu=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14495f2",
   "metadata": {},
   "source": [
    "### Universal Text Extractor (Image / Typed PDF / Scanned Handwritten PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "264e723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image, ImageEnhance\n",
    "import fitz  # PyMuPDF\n",
    "import numpy as np\n",
    "\n",
    "def easyocr_image(image: Image.Image):\n",
    "    image = image.convert(\"L\")  # grayscale\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(2.0)  # increase contrast\n",
    "    results = reader.readtext(np.array(image), detail=0, paragraph=True)\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "def extract_text(file_path):\n",
    "    ext = Path(file_path).suffix.lower()\n",
    "\n",
    "    if ext == \".pdf\":\n",
    "        doc = fitz.open(file_path)\n",
    "        full_text = \"\"\n",
    "        for i, page in enumerate(doc):\n",
    "            typed_text = page.get_text().strip()\n",
    "            if len(typed_text) > 50:\n",
    "                full_text += typed_text + \"\\n\"\n",
    "            else:\n",
    "                pix = page.get_pixmap(dpi=400)\n",
    "                img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "                full_text += easyocr_image(img) + \"\\n\"\n",
    "        return full_text.strip()\n",
    "\n",
    "    elif ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        img = Image.open(file_path)\n",
    "        return easyocr_image(img)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {ext}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f79e3e",
   "metadata": {},
   "source": [
    "### Chunk the Extracted Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad92fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=100, overlap=20):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe4d7c3",
   "metadata": {},
   "source": [
    "### Create Vector Embeddings and BM25 Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e1ffb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def build_indexes(chunks):\n",
    "    embeddings = embedding_model.encode(chunks)\n",
    "    tokenized_chunks = [chunk.split(\" \") for chunk in chunks]\n",
    "    bm25 = BM25Okapi(tokenized_chunks)\n",
    "    return embeddings, bm25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8c235",
   "metadata": {},
   "source": [
    "### Adaptive Retrieval (Vector + Keyword Fusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80b11ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def adaptive_retrieve(query, chunks, embeddings, bm25, top_k=3, alpha=0.5):\n",
    "    query_embedding = embedding_model.encode([query])[0]\n",
    "    vector_scores = cosine_similarity([query_embedding], embeddings)[0]\n",
    "    keyword_scores = bm25.get_scores(query.split())\n",
    "\n",
    "    vector_scores = (vector_scores - np.min(vector_scores)) / (np.max(vector_scores) - np.min(vector_scores) + 1e-8)\n",
    "    keyword_scores = (keyword_scores - np.min(keyword_scores)) / (np.max(keyword_scores) - np.min(keyword_scores) + 1e-8)\n",
    "\n",
    "    combined_scores = alpha * vector_scores + (1 - alpha) * keyword_scores\n",
    "    top_indices = np.argsort(combined_scores)[::-1][:top_k]\n",
    "    return [chunks[i] for i in top_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0a3952",
   "metadata": {},
   "source": [
    "### Ask Groq API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f28348d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "groq_client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "def ask_groq(prompt):\n",
    "    response = groq_client.chat.completions.create(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540514bd",
   "metadata": {},
   "source": [
    "### Preview Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2756923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\my files\\vs project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Preview Extracted Text:\n",
      "\n",
      "Cwe } Iio [03 Akb Hlaoam See : 22 Appianmext-2 T0 ; 26/4892642 9k) Enxplai ~ki We\"need Yood, ;  , (6) Nam ‚Ç¨ Ae` enexttial and MOn enpewtial amino acidb ~ ;; Lmlysi $ : Anc (:} 1,, | 0.266.9)61 6' ' W} ;, 4 Food ia ' #e: mox-ncwtee pf 'enendi: It in @nn  emtial (on W to ake {ood 2o beeawe: 3 . he_Poin of: body ) Photection lenendj 1  dtovt ladairt . dineanea . ) ' healky , nAxt\" otnont bonen , awd l cl the Yeell blood; , F Fcodo Jien w al 1 0 cf ,f 356360 Iutfve JeA-iuezerVe # ot bodj: Foo & fy Dlppa; en enengt_ka Piad-etion pf hest and 'Jwf)k . 3 all 04 ackiv tien iX Ow b6lj' # in (apen enh enkd fa {nonk 6( human 46lj' i4 i @n^ enticy Jon   d:]y wean and /eci in O ve-' 18 alo Phokeetn ot bodj 8hom\n",
      "Iv6 CH 1081 ; : (r\n",
      "{^1ii ;',,1') , ' c{', ~ v; i| Nan iol tjpen '{( ofvdlneaser, exas) pke : K }   :0c wVJ ' ~hicketo , etc Ir deneal Wodj - i{ ia Ixollved ;n Ane {nekon o al #ke bol- Plocenlen. Food i indinedly Reldded t6 #e * meta_bol}nm Ow&I vAj' Food  ha 9' 0 mindtwe 0f abnlancen' . Thej \n"
     ]
    }
   ],
   "source": [
    "file_path = \"Akib Hasan 2011892642.pdf\"  # Your uploaded file\n",
    "extracted_text = extract_text(file_path)\n",
    "\n",
    "print(\"üìù Preview Extracted Text:\\n\")\n",
    "print(extracted_text[:1000])  # Show first 1000 characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de264d6",
   "metadata": {},
   "source": [
    "### Full RAG Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13453b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\my files\\vs project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\my files\\vs project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, diabetes is a condition where the body has abnormally high levels of glucose in the blood, making it difficult to metabolize glucose and regulate blood sugar levels.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"Akib Hasan 2011892642.pdf\"  # or \"note.jpg\", etc.\n",
    "text = extract_text(file_path)\n",
    "chunks = chunk_text(text)\n",
    "embeddings, bm25 = build_indexes(chunks)\n",
    "\n",
    "query = \"What is diabetes?\"\n",
    "retrieved = adaptive_retrieve(query, chunks, embeddings, bm25)\n",
    "\n",
    "context = \"\\n\".join(retrieved)\n",
    "final_prompt = f\"Use the context below to answer the question:\\n\\nContext:\\n{context}\\n\\nQuestion: {query}\"\n",
    "\n",
    "response = ask_groq(final_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca925f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
